1. MPI send / receive: 
- With MPI_Ssend() and MPI_Recv() the code does not finish since aperently, 
Ssend does wait for confirmation of receiving, which id does not get. 

working code: 
    // Loop over the number of processes
    for (int i = 0; i < size; i++) {
        if (my_rank % 2 == 0) {
            MPI_Recv(&recv_rank, 1, MPI_INT, left_rank, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);
            MPI_Ssend(&send_rank, 1, MPI_INT, right_rank, 0, MPI_COMM_WORLD);
        } else {
            MPI_Ssend(&send_rank, 1, MPI_INT, right_rank, 0, MPI_COMM_WORLD);
            MPI_Recv(&recv_rank, 1, MPI_INT, left_rank, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);
        }
        
        send_rank = recv_rank;
        
        my_sum += recv_rank;
    }

-> srun -n 4 ./ring
I am processor 1 out of 4, my left neighbor is 0 and the sum is 6
I am processor 2 out of 4, my left neighbor is 1 and the sum is 6
I am processor 3 out of 4, my left neighbor is 2 and the sum is 6
I am processor 0 out of 4, my left neighbor is 3 and the sum is 6

MPI non-blocking send / recv:

- Irecv() -> Isend() -> Waitall 

srun -n 4 ./ring_2
srun: job 5891913 queued and waiting for resources
srun: job 5891913 has been allocated resources
I am processor 0 out of 4, my left neighbor is 3, the sum is 6 and it took me 0.000090 seconds
I am processor 1 out of 4, my left neighbor is 0, the sum is 6 and it took me 0.000094 seconds
I am processor 3 out of 4, my left neighbor is 2, the sum is 6 and it took me 0.000085 seconds
I am processor 2 out of 4, my left neighbor is 1, the sum is 6 and it took me 0.000078 seconds



- Isend() -> Irecv -> Waitall 

srun -n 4 ./ring_2
I am processor 0 out of 4, my left neighbor is 3, the sum is 6 and it took me 0.000081 seconds
I am processor 2 out of 4, my left neighbor is 1, the sum is 6 and it took me 0.000080 seconds
I am processor 3 out of 4, my left neighbor is 2, the sum is 6 and it took me 0.000073 seconds
I am processor 1 out of 4, my left neighbor is 0, the sum is 6 and it took me 0.000079 seconds


-> The nonblocking code has less risk of locking up. It is a bit more flexible and forgiving. 

Using a cartesian communicator. 

srun -n 4 ring_3
Process 1 (cart rank 1): left=0, right=2, sum=6, time=0.000083 sec
Process 2 (cart rank 2): left=1, right=3, sum=6, time=0.000083 sec
Process 0 (cart rank 0): left=3, right=1, sum=6, time=0.000078 sec
Process 3 (cart rank 3): left=2, right=0, sum=6, time=0.000086 sec

This is a lot simpler and more robust since we rely on a general solution by MPI. 
